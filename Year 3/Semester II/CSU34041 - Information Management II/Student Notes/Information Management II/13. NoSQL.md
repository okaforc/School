[[CSU 34041 - 13 - NoSQL.pdf]]
## Relational model
- Started to be in use in 1970
- Since then, generally default choice
	- Persistence
	- Concurrency
	- Integration

### Limitations
1. Impedence mismatch: complex objects are not suited to being represented in a relational way
2. Application and integration: the database works as a integration database. However, in this scenario the structure of the database tend to be more complex
3. Scaling up vs scaling out (parallel): tends towards scaling up rather than out, not good for where technology currently is
4. Depend on a pre-filter
5. Based on a 1970s view of things


## What do we need to be able to work with?
### 1. Data size
- Big!

### 2. Connectedness
![[Pasted image 20230420094433.png]]

### 3. Semi-structure
- Individualisation of content
	- Eg, in 1970s, salary list had exactly 1 job 
	- Now need like 5-10 job columns
- All encompassing "entire world views"
	- More data about each entity
- Accelerated by decentralisation of content generation in web 2.0

### 4. Architecture
![[Pasted image 20230420094735.png]]
From:
1. 1 DB with 1 application 
2. to 1 DB with many applications connected
3. to decoupled services
	- Many DB, many services
	- Not connected
	- Multicore, parallel/distributed
	- Cloud
	- No schema

#### Why Moore's law fucks over DBs
**Moore's law:** the number of transistors in a dense integrated circuit doubles about every two years
- Great for chip based technologies
- Awful for disks (which is where databases live!)
	- Accessing disks take ~8 million times longer than one instruction

### 5. Cloud computing
- Uses virtualisation to run many copies of an OS on one piece of hardware
- Especially used for data storage and computing power, without direct active management by the user

#### History
- AWS explosion in 2006
- Cost per GB/Month for Stable Storage 
	- ~$5 per GB down to 2 cents per GB 
- Unlimited Storage 
- Purchased in GB chunks 
- Pay only for what you use

##### Effect
This results in
1. No capital expenditure (CAPEX) - sinds to buy/upgrade physical assets
2. No data centre
3. Availability of scale
4. Utility Pricing (pay per use)

##### Change in data approach
From
`Filter-Store-Distribute`
- Used in Encyclopedias, Libraries, Newspapers, Banks, etc
- Because of storage & bandwidth limits

To
`Store-Filter-Distribute`

## Scaling databases!
Big data gives 2 options

### 1. Scale up
- Bigger computers
- More:
	- Processors
	- Disk storage
	- Memory
- Expensive!

### 2. Scale out
- Cloud computing!
- Lots of computers
- Horizontal scaling
- Based on data partitioning (divide database across multiple machines)
- Cheaper
- More resilient

Problem: relational DBs not designed to run on clusters

#### Scaling out with relational DBs
- Clustered DBs (Oracle RAC/Microsoft SQL Server) work on shared disk subsystem
- Then, the relational DBMS (RDBMS) can run on a seperate server with different sets of data via sharding
	- Needs application to control shared DB
- Lose these across shards
	- Querying power
	- Referential integrity
	- Transaction
	- Consistency
- Also licensing cost!

This just doesn't make sense!

#### NoSQL
Born out of:
1. Need to handle large data volumes
	- Forces shift to building using clusters
2. Difficulties of making application code play well with relational DBs

## NoSQL
### Why?
Explosion of unstructure data
1. Big
	- Exceeds the processing capacity of normal DB systems
2. Might move too fast
3. Doesn't fit the structure

Need an alternative way to process it to get patterns and info, handling
1. Velocity
2. Variety
3. Volume

### When?
- Started in 90s
- Actual work
	1. 2004: Google started BigTable
	2. 2007: Amazon Dynamo
	3. 2009: Meetup to discuss non-relational DBs

### Key characteristics (no real definition)
1. Non relational
2. No SQL for the query language
	- (although the query languages might look similar)
3. No schema
4. Usually open source
5. Distributed - driven by requirements of running on cluster
6. Do *not* use **ACID** transactions (Atomicity, Consistency preservation, Integrity, Durability)

#### Requirements
1. Data durability
2. Consistent performance
3. Graceful degradation under load
4. Distributed computing

#### Distributed Computing
- In distributed system we have a network of autonomous computers that communicate with each other in order to achieve a goal
- The computers in a distributed system are independent and do not physically share memory or processor
- Much more power 
- Cheaper 
- More resilience

But, you need one of these:

##### Distribution Models
###### Replication
Same data is replicated and copied over multiple nodes.
Types:
1. "Master-slave" (I'm gonna call it Publisher-Subscriber based on this https://learn.microsoft.com/en-us/sql/relational-databases/replication/publish/replication-publishing-model-overview?view=sql-server-ver16)
	- Scaling up by adding subscribers
	- Processing of incoming data is limited by the publisher
	- Has read resilience
	- Inconsistency problem on read
2. Peer-to-peer
	- All replicas have equal weight
	- All replicas can accept writes
	- Scale by adding nodes
	- Can have node failure without losing write capability!
	- Inconsistency problem on write

###### Sharding
- Different data on different nodes (horizontal scalability)
- Each server is a single source for its subset of data
- Ideal setting has the user talk to one server to access data
	- Has data which will be accessed together stored together
- Many NoSQL DBs offer auto-sharding
- Scales read/write on different nodes of the same cluster
- *No resilience if used alone*
	- If a node fails
	- => data unavailable

###### Combined
1. Publisher-subscriber & sharding
	- Each data has a publisher
	- Multiple publishers overall
2. P2P & sharding
	- Common for column-family DBs
	- Form of replication for shards

## CAP theorem
Only 2 of 3 can be guaranteed
![[Pasted image 20230420105947.png]]
1. **Consistency:** All nodes see the same data at the same time
2. **Availability:** A guarantee that every request receives a response about whether it succeeded or failed
3. **Partition tolerance:** The system continues to operate despite arbitrary partitioning due to network failures
	- When a network partition fails, need to decide between
		1. Cancel operation - decrease availability, ensure consistency
		2. Proceed with operation - risk inconsistency, ensure availability 

### CP (Consistency and Partition Tolerance)
MongoDB does this

### AP (Availability and Partition Tolerance)
For when you want availability as well!

#### Eventual Consistency
- Consistency model used in distributed computing
- Achieve high availability
- Informally guarantees if no new updates are made to a given data item, *eventually* all accesses to that item will return to the last updated value
- **Reconciliation:**
	- Choosing an appropriate final state when concurrent updates have occurred
	- A problem

### CA
- A single-server system is the obvious example of a CA system
	- Has Consistency and Availability
	- Not Partition tolerance: 
		- A single machine can’t partition, so it does not have to worry about partition tolerance. 
- There’s only one node—so if it’s up, it’s available. 
- Being up and keeping consistency is reasonable. 
- This is the world that most relational database systems live in.

#### CA Cluster?
- Theoretically possible
- If a partition ever happens in a cluster
	- All nodes in the cluster would go down
	- By the usual definition of “available,” this would mean a lack of availability, but this is where CAP’s special usage of “availability” gets confusing
- **Availability:** every request received by a non failing node in the system must result in a response
	- Means a failure is allowed
- So you *can* but why would you?


## NoSQL vs SQL/Relational DBs

### Transaction Models
#### SQL - ACID
1. Atomic: Everything in a transaction succeeds or the entire transaction is rolled back 
2. Consistent: A transaction cannot leave the database in an inconsistent state 
3. Isolated: Transactions cannot interfere with each other 
4. Durable: Completed transactions persist, even when servers restart etc.

#### NoSQL - BASE
1. **B**asic **A**vailability: An application works basically all the time 
2. Soft-state: It does not have to be consistent all the time 
3. Eventual consistency: It will be in some known-state state eventually

- Each node is always available to serve requests. 
- Data modifications are propagated in the background to other nodes. 
- System may be inconsistent, but the data is still largely accurate.

### NoSQL vs SQL/Relational DBs
#### Pros
1. Flexible schema
2. Simple API
3. Scalable
4. Distributed & replicated storage
5. Cheap

#### Cons
1. Not ACID compliant
2. No standards
3. Eventual consistency
4. Early stage products

## Data Model
- Representation of how we perceive and manipulate our data
- Describes how we interact with the data
	- Represents data elements under analysis
	- & how they interact with each other

### Storage model
Different!
How the database stores and manipulates the data internally
 

### Types of NoSQL
Also, there are of course hybrids!

#### Key-value stores
![[Pasted image 20230420112004.png]]
1. Maps keys to values
2. Values treated as blobs 
	- Allowed to be complex objects! (list, map, etc)
3. Single Index
4. Consistency for operations on a single key
5. Fast and scalable!
6. Inefficient at aggregate queries:
	- "“all the carts worth $100 or more"
	- Also bad at relationships (same reason)
7. Good for shopping carts, user profiles and preferences, storing session information

#### Document stores
![[Pasted image 20230420111951.png]]
- Like a hash with 1 ID and many values
- EG: JSON
	- JavaScript Object Notation
	- An associative array
	- Key-value pairs
	- Values can be documents (another JSON object) or arrays
	- Arrays can contain documents 
- Data is *implicitly denormalised*
	- Close to a single table!
- Document databases allow indexing of documents
	- With primary key/identifier
	- AND based on its properties

##### Easier!
![[Pasted image 20230420112356.png]]

##### Features
1. Rich Queries
	- Find Paul’s cars 
	- Find everybody who owns a car built between 1970 and 1980
2. Geospatial
	- Find all of the car owners in London
3. Text Search
	- Find all the cars described as having leather seats
4. Aggregation
	- What’s the average value of Paul’s car collection
5. Map reduce
	- For each make and model of car, how many exist?

#### Column stores
![[Pasted image 20230420112616.png]]
1. Stores data as columns rather than rows (as in relational)
	1. Columns organised in column family
	2. Each column belongs to 1 column family
	3. Column acts as a unit for access
	4. Particular column family will be accessed together
	5. Column can vary in width
2. Efficient at column ordered operations
3. Not great at row based queries
4. Adding columns is inexpensive and done on a row-by-row basis
5. Each row can have a different set of columns, or none at all, allowing tables to remain sparse without incurring a storage cost for null values

##### Relational/Row Order vs Column
###### Relational 
![[Pasted image 20230420112849.png]]

###### Column
![[Pasted image 20230420112930.png]]
- Storage as columns
- Primary key is data, mapped from row ids in relational

##### Pros and Cons of Relational and Column
###### Relational is good for
1. Queries returning small subsets of rows
2. Queries that use a large subset of row data
3. e.g. find all employee data for employees with salary > 12000

###### Column is good for
1. Queries that require just 1 column of data
2. Queries that require a small subset of row data
3. E.g. Give me the total salary outlay for all staff
4. Null values without storage waste!

#### Graph stores
![[Pasted image 20230420113159.png]]
1. Composed by nodes connected by edges
	1. Nodes represent entities
	2. Edges represent relationships between entities
	3. Nodes and edges can have properties
2. Querying a graph database means traversing the graph by following relationships

**Pros:**
- Representing objects of the real world that are highly interconnected 
- Traversing the relationships in these data models is cheap

##### Vs Relational Databases
- Relational databases are not ideally suited to representing relationships
- Relationship implemented through foreign keys 
	- Expensive joins required to navigate relationships 
	- Poor performance for highly connected data models

### Hadoop
- Hadoop is a Map/Reduce Framework 
- Used to partition computation on large datasets 
- Used where you need to analyse very large volumes of the data 
- E.g. 
	- Count all the links on all the web pages in Ireland 
	- Calculate the overnight interest on every account 
	- Analyse the recommendations based on yesterday’s purchases
- Used *with* NoSQL DB

### Example 
![[Pasted image 20230420113624.png]]
